{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1- Install ***transformers*** library in order to use ***huggingface*** pre-trained models."
      ],
      "metadata": {
        "id": "9qC7F-hvXcd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "UR-sJNfdMluj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Import ***transformers*** library"
      ],
      "metadata": {
        "id": "AM72H8p5XpqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kAGABrtcMgPw"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- The `pipeline` downloads and caches a the pre-trained model and tokenizer for text classificaiton. Now we can use the `classifier` for the target text:"
      ],
      "metadata": {
        "id": "x-FT_icMXu42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"text-classification\", model=\"ivanlau/language-detection-fine-tuned-on-xlm-roberta-base\")"
      ],
      "metadata": {
        "id": "BFKmlyq3Mh02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4- Read the target text or document."
      ],
      "metadata": {
        "id": "gLn5rSPEYOfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text = 'how are you sir.je suis de france. وانت.'"
      ],
      "metadata": {
        "id": "pQn2neLxMh4H"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5- Apply the segmentation technique that you need, in this script, we segmented based on `dot` mark."
      ],
      "metadata": {
        "id": "11L13pvwYSe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation = Text.split('.')"
      ],
      "metadata": {
        "id": "M5jfNbeuNgAc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6- The main part is to feed the segmented part of text to the pre-trained model in order to detect its `language`."
      ],
      "metadata": {
        "id": "ELfR9c_ZYbMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for i in range(len(segmentation)):\n",
        "  if not segmentation[i]:\n",
        "    break\n",
        "  result = classifier(segmentation[i])\n",
        "  out= { 'Text': segmentation[i], 'lang':result[0]['label']}\n",
        "  output.append(out)"
      ],
      "metadata": {
        "id": "TvFXYvfQNlLi"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7- Finally, the output is in `json` format and the content sorted based on its appearance in the text."
      ],
      "metadata": {
        "id": "htsGgp07YmFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q72PgT1wTH9v",
        "outputId": "9799398b-3ab5-42f7-fa5d-0703aa32b3ed"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Text': 'how are you sir', 'lang': 'English'},\n",
              " {'Text': 'je suis de france', 'lang': 'French'},\n",
              " {'Text': ' وانت', 'lang': 'Persian'}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}